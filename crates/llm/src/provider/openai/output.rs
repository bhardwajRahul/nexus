use serde::Deserialize;

use crate::messages::{ChatChoice, ChatCompletionResponse, ChatMessage, FinishReason, Model, ObjectType, Usage};

/// Response from OpenAI Chat Completions API.
///
/// This struct represents the response format from the `/v1/chat/completions` endpoint
/// as documented in the [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat/object).
#[derive(Debug, Deserialize)]
pub(super) struct OpenAIResponse {
    /// A unique identifier for the chat completion.
    pub(super) id: String,

    /// The object type, which is always `chat.completion`.
    #[allow(dead_code)]
    pub(super) object: String,

    /// The Unix timestamp (in seconds) of when the chat completion was created.
    pub(super) created: u64,

    /// A list of chat completion choices.
    /// Can be more than one if `n` is greater than 1 in the request.
    pub(super) choices: Vec<OpenAIChoice>,

    /// Usage statistics for the completion request.
    /// Includes information about tokens used for prompt, completion, and total.
    pub(super) usage: Usage,
}

/// The reason why OpenAI stopped generating tokens.
#[derive(Debug, Deserialize, PartialEq)]
pub(super) enum OpenAIFinishReason {
    /// Natural stop point or stop sequence encountered.
    #[serde(rename = "stop")]
    Stop,
    /// Maximum token limit reached.
    #[serde(rename = "length")]
    Length,
    /// Content filtered for safety/policy reasons.
    #[serde(rename = "content_filter")]
    ContentFilter,
    /// Model invoked a tool/function.
    #[serde(rename = "tool_calls")]
    ToolCalls,
    /// Model invoked a function (legacy).
    #[serde(rename = "function_call")]
    FunctionCall,
    /// Any other finish reason.
    /// Captures the actual string value for forward compatibility.
    #[serde(untagged)]
    Other(String),
}

/// A chat completion choice returned by the model.
///
/// Represents one possible completion for the given input.
/// Multiple choices can be returned if requested via the `n` parameter.
#[derive(Debug, Deserialize)]
#[serde(rename_all = "snake_case")]
pub(super) struct OpenAIChoice {
    /// The index of this choice in the list of choices.
    pub(super) index: u32,

    /// A chat completion message generated by the model.
    pub(super) message: ChatMessage,

    /// The reason the model stopped generating tokens.
    pub(super) finish_reason: Option<OpenAIFinishReason>,
}

/// Response from OpenAI Models API listing available models.
///
/// This struct represents the response format from the `/v1/models` endpoint
/// as documented in the [OpenAI API Reference](https://platform.openai.com/docs/api-reference/models/list).
#[derive(Debug, Deserialize)]
pub(super) struct OpenAIModelsResponse {
    /// List of available models.
    pub(super) data: Vec<OpenAIModel>,
}

/// Describes an OpenAI model offering that can be used with the API.
///
/// Contains metadata about a specific model including its capabilities and ownership.
#[derive(Debug, Deserialize)]
#[serde(rename_all = "snake_case")]
pub(super) struct OpenAIModel {
    /// The model identifier, which can be referenced in the API endpoints.
    /// Examples: "gpt-4", "gpt-3.5-turbo", "text-davinci-003"
    pub(super) id: String,

    /// The object type, which is always "model".
    #[allow(dead_code)]
    pub(super) object: String,

    /// The Unix timestamp (in seconds) when the model was created.
    pub(super) created: u64,

    /// The organization that owns the model.
    /// Examples: "openai", "openai-internal", "system"
    pub(super) owned_by: String,
}

impl From<OpenAIFinishReason> for FinishReason {
    fn from(reason: OpenAIFinishReason) -> Self {
        match reason {
            OpenAIFinishReason::Stop => FinishReason::Stop,
            OpenAIFinishReason::Length => FinishReason::Length,
            OpenAIFinishReason::ContentFilter => FinishReason::ContentFilter,
            OpenAIFinishReason::ToolCalls | OpenAIFinishReason::FunctionCall => FinishReason::ToolCalls,
            OpenAIFinishReason::Other(s) => {
                log::debug!("Unknown finish reason from OpenAI: {s}");
                FinishReason::Other(s)
            }
        }
    }
}

impl From<OpenAIChoice> for ChatChoice {
    fn from(choice: OpenAIChoice) -> Self {
        Self {
            index: choice.index,
            message: choice.message,
            finish_reason: choice.finish_reason.map(Into::into).unwrap_or(FinishReason::Stop),
        }
    }
}

impl From<OpenAIResponse> for ChatCompletionResponse {
    fn from(response: OpenAIResponse) -> Self {
        Self {
            id: response.id,
            object: ObjectType::ChatCompletion,
            created: response.created,
            model: String::new(), // Will be set by the provider
            choices: response.choices.into_iter().map(Into::into).collect(),
            usage: response.usage,
        }
    }
}

impl From<OpenAIModel> for Model {
    fn from(model: OpenAIModel) -> Self {
        Self {
            id: model.id,
            object: ObjectType::Model,
            created: model.created,
            owned_by: model.owned_by,
        }
    }
}
